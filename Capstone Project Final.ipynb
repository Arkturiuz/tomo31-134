{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The goal that I set for this project is to create the classifiers for highly rated venues on Foursquare. The problem is that there are a number of venues with the missing values for the rating although the rating scores could be used as a valuable reference for tourists outside the location to determine their destination. Therefore, the purpose of this project is to create the algorithm to identify the venues with the possibility of being highly rated. In addition, in order to improve the accuracy of the classifier, 4 different classification techniques which are Decision Tree, SVM, Logistic Regression, and KNN have been built and compared since the difference in the models lead to the variation in the predictive accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "The data used for creating the algorithm is imported from Foursquare via API, resulting in extracting the data from 53 venues located in New York, Tokyo, Paris, London, Hong Kong, Australia, Brazil, and Shang Hai. For the target variable of the classification model, a categorical variable, rating category, with 3 levels which are high, mid, and low, is created based on the existing rating data. Regarding this, the label, high, is assigned to a rating greater or equal to 8.3, the label, mid, is assigned to a rating below 8.3 and above 6.5, and the label, low, is assigned to a rating less or equal to 6.5. This label assignment is based on the values on the 3rd quartile and 1st quartile of the rating variable. For the types of data being used for building the model, the total number of variables being used is 57 which are not related to rating such as price message and listed count."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "Code\n",
    "The code is based on 3 parts which are 1) data preprocessing, 2) modeling building, and 3) model evaluation\n",
    "\n",
    "### 1) Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "from sklearn import preprocessing as pr\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from geopy.geocoders import Nominatim\n",
    "import requests\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data preprocessing, the data is first imported via Foursquare API. Regarding the data imported from Foursquare, there are 2 categories of information requested through API which are general venue info by the given cities and specific venue information including rating scores. Due to the limitation on the number of daily calls available for each account, several accounts have been created for importing data and integrated and saved in a format of csv. Therefore, even though the code for importing the Foursquare has been provided here for the transparency of the coding procedure, the actual data used for the analysis has been imported from the local environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample code for data requests on Foursquare API\n",
    "##### Import venue info\n",
    "CLIENT_ID = 'your Foursquare ID'\n",
    "CLIENT_SECRET = 'your Client Secret' \n",
    "VERSION = '20190730'\n",
    "\n",
    "url_NY = \"https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll=40.7127281,-74.0060152&v={}\".format(CLIENT_ID, CLIENT_SECRET, VERSION) \n",
    "results_NY = requests.get(url_NY).json()\n",
    "results_NY\n",
    "\n",
    "url_TK = \"https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll=35.652832,139.839478&v={}\".format(CLIENT_ID, CLIENT_SECRET, VERSION) \n",
    "results_TK = requests.get(url_TK).json()\n",
    "results_TK\n",
    "\n",
    "url_Paris = \"https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll=48.8566101,2.3514992&v={}\".format(CLIENT_ID, CLIENT_SECRET, VERSION) \n",
    "results_Paris = requests.get(url_Paris).json()\n",
    "results_Paris\n",
    "\n",
    "url_Ld = \"https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll=51.509865,-0.118092&v={}\".format(CLIENT_ID, CLIENT_SECRET, VERSION) \n",
    "results_Ld = requests.get(url_Ld).json()\n",
    "results_Ld\n",
    "\n",
    "url_HK = \"https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll=22.28552,114.15769&v={}\".format(CLIENT_ID, CLIENT_SECRET, VERSION) \n",
    "results_HK = requests.get(url_HK).json()\n",
    "results_HK\n",
    "\n",
    "url_AS = \"https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll=-33.865143,151.209900&v={}\".format(CLIENT_ID, CLIENT_SECRET, VERSION) \n",
    "results_AS = requests.get(url_AS).json()\n",
    "results_AS\n",
    "\n",
    "url_BR = \"https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll=-23.533773,-46.625290&v={}\".format(CLIENT_ID, CLIENT_SECRET, VERSION) \n",
    "results_BR = requests.get(url_BR).json()\n",
    "results_BR\n",
    "\n",
    "url_SH = \"https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll=31.22222,121.45806&v={}\".format(CLIENT_ID, CLIENT_SECRET, VERSION) \n",
    "results_SH = requests.get(url_SH).json()\n",
    "results_SH\n",
    "\n",
    "##### Merge venue info\n",
    "df_frames = [df_TK, df_NY, df_Paris, df_Ld, df_HK, df_AS, df_BR, df_SH]\n",
    "df_con = pd.concat(df_frames, axis=0, join = 'inner')\n",
    "df_con.to_csv('df_con.csv')\n",
    "\n",
    "filtered_columns = ['name', 'categories'] + [col for col in df_con.columns if col.startswith('location.')] + ['id']\n",
    "df_con_filtered = df_con.loc[:, filtered_columns]\n",
    "\n",
    "##### keep only columns that include venue name, and anything that is associated with location\n",
    "filtered_columns = ['name', 'categories'] + [col for col in df_con.columns if col.startswith('location.')] + ['id']\n",
    "df_con_filtered = df_con.loc[:, filtered_columns]\n",
    "\n",
    "##### function that extracts the category of the venue\n",
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']\n",
    "\n",
    "##### filter the category for each row\n",
    "df_con_filtered['categories'] = df_con_filtered.apply(get_category_type, axis=1)\n",
    "\n",
    "##### clean column names by keeping only last term\n",
    "df_con_filtered.columns = [column.split('.')[-1] for column in df_con_filtered.columns]\n",
    "df_con_filtered['categories'].nunique()\n",
    "df_con_filtered = pd.DataFrame(df_con_filtered)\n",
    "df_con_filtered.to_csv('df_con_filtered.csv')\n",
    "list_id = df_con_filtered['id']\n",
    "list_id = list_id.tolist()\n",
    "\n",
    "##### Getting specific venue info including\n",
    "id_list = df_con_filtered['id'].values.tolist()\n",
    "df_test = []\n",
    "for i in id_list:\n",
    "    url_test = 'https://api.foursquare.com/v2/venues/{}?client_id={}&client_secret={}&v={}'.format(i, CLIENT_ID, CLIENT_SECRET, VERSION)\n",
    "    results_test = requests.get(url_test).json()\n",
    "    venue_test = results_test['response']['venue']\n",
    "    df_test.append(venue_test)\n",
    "\n",
    "##### keep the rows with  rating input\n",
    "df_test_con.drop_duplicates(subset = 'id', keep = False, inplace = True)\n",
    "df_con_rating = df_test_con.dropna(subset=['rating'])\n",
    "df_data = df_con_rating[['id','rating', 'ratingSignals', 'likes.count', 'listed.count', 'photos.count', 'price.message', 'price.tier', 'tips.count', 'page.user.tips.count']]\n",
    "df_data = df_data.merge(df_con_filtered[['id', 'categories', 'cc', 'lat', 'lng']], on = 'id', how = 'inner')\n",
    "df_data.set_index('id', inplace = True)\n",
    "\n",
    "##### Replacing missing values with average scores â€»replace missing values with means for price.tier &  page.user.tips.count and replace missing values with most frequent value for price.message\n",
    "missing_data = df_data.isnull()\n",
    "\n",
    "for i in missing_data.columns.values.tolist():\n",
    "    print(i)\n",
    "    print (missing_data[i].value_counts())\n",
    "    print(\"\")\n",
    "av_price_tier = df_data['price.tier'].mean(axis = 0)\n",
    "df_data['price.tier'].replace(np.nan, av_price_tier, inplace = True)\n",
    "av_page_user_tips_count = df_data['page.user.tips.count'].mean(axis=0)\n",
    "df_data['page.user.tips.count'].replace(np.nan, av_page_user_tips_count, inplace = True)\n",
    "df_data['price.message'].replace(np.nan, 'Moderate', inplace = True)\n",
    "\n",
    "for i in missing_data.columns.values.tolist():\n",
    "    print(i)\n",
    "    print (missing_data[i].value_counts())\n",
    "    print(\"\")\n",
    "\n",
    "##### One hot encoding\n",
    "df_data_dummies = pd.get_dummies(df_data)\n",
    "df_data_dummies.to_csv('df_data_dummies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import the merged data from the local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'ratingSignals', 'likes.count', 'listed.count',\n",
       "       'photos.count', 'price.tier', 'tips.count', 'page.user.tips.count',\n",
       "       'lat', 'lng', 'price.message_Cheap', 'price.message_Expensive',\n",
       "       'price.message_Moderate', 'price.message_Very Expensive',\n",
       "       'categories_Bar', 'categories_Beer Bar', 'categories_Bistro',\n",
       "       'categories_CafÃ©', 'categories_Cantonese Restaurant',\n",
       "       'categories_Chinese Restaurant', 'categories_Church',\n",
       "       'categories_City Hall', 'categories_Cocktail Bar',\n",
       "       'categories_Coffee Shop', 'categories_Cosmetics Shop',\n",
       "       'categories_Department Store', 'categories_Electronics Store',\n",
       "       'categories_French Restaurant', 'categories_Fried Chicken Joint',\n",
       "       'categories_German Restaurant', 'categories_Hotel',\n",
       "       'categories_Japanese Restaurant', 'categories_Movie Theater',\n",
       "       'categories_Multiplex', 'categories_Park',\n",
       "       'categories_Pedestrian Plaza', 'categories_Pizza Place',\n",
       "       'categories_Plaza', 'categories_Post Office', 'categories_Restaurant',\n",
       "       'categories_Salon / Barbershop', 'categories_Shoe Store',\n",
       "       'categories_Shopping Mall', 'categories_Soba Restaurant',\n",
       "       'categories_Souvenir Shop', 'categories_Spanish Restaurant',\n",
       "       'categories_Steakhouse', 'categories_Supermarket',\n",
       "       'categories_Track Stadium', 'categories_Train Station',\n",
       "       'categories_Vegetarian / Vegan Restaurant',\n",
       "       'categories_Vietnamese Restaurant', 'categories_Women's Store', 'cc_AU',\n",
       "       'cc_FR', 'cc_GB', 'cc_HK', 'cc_JP', 'cc_US'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv('local path') ##local path for the merged data\n",
    "df_data.set_index('id', inplace = True)\n",
    "df_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining a target variable & explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['rating'].describe() #high = >=8.3, mid = 8.3 > x > 6.5, low = <=6.5 \n",
    "\n",
    "rating_category = []\n",
    "\n",
    "for i, r in df_data.iterrows():\n",
    "    if int(df_data.loc[i, ['rating']]) >= 8.3:\n",
    "        rating_category.append('high')\n",
    "    elif int(df_data.loc[i, ['rating']]) < 8.3 and int(df_data.loc[i, ['rating']])> 6.5:\n",
    "        rating_category.append('mid')\n",
    "    elif int(df_data.loc[i, ['rating']]) < 6.5:\n",
    "        rating_category.append('low')\n",
    "        \n",
    "df_data['rating_category'] =  rating_category\n",
    "x = df_data.iloc[:, 2:58]\n",
    "y = df_data['rating_category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standardization & Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocessing.StandardScaler().fit(x).transform(x)\n",
    "x_trainset, x_testset, y_trainset, y_testset = train_test_split(x, y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "['low' 'mid' 'mid' 'low' 'mid']\n",
      "id\n",
      "4bbf498ab083a593a620a3e9    low\n",
      "4b05caf7f964a5206de322e3    mid\n",
      "58d800df9435a979b8a645fa    mid\n",
      "5614b48d498ea3525f672509    low\n",
      "4b0588def964a520b9dd22e3    mid\n",
      "Name: rating_category, dtype: object\n"
     ]
    }
   ],
   "source": [
    "rating_category_tree = dtc(criterion = 'entropy', max_depth = 3)\n",
    "rating_category_tree.fit(x_trainset, y_trainset)\n",
    "tree_pred = rating_category_tree.predict(x_testset)\n",
    "print(rating_category_tree)\n",
    "print (tree_pred [0:5])\n",
    "print (y_testset [0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
      "           weights='uniform')\n",
      "['low' 'mid' 'low' 'low' 'low']\n",
      "id\n",
      "4bbf498ab083a593a620a3e9    low\n",
      "4b05caf7f964a5206de322e3    mid\n",
      "58d800df9435a979b8a645fa    mid\n",
      "5614b48d498ea3525f672509    low\n",
      "4b0588def964a520b9dd22e3    mid\n",
      "Name: rating_category, dtype: object\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "neigh = KNeighborsClassifier(n_neighbors = k).fit(x_trainset,y_trainset)\n",
    "KNN_pred = neigh.predict(x_testset)\n",
    "KNN_pred[:5]\n",
    "print (neigh)\n",
    "print (KNN_pred[0:5])\n",
    "print (y_testset[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "['high' 'mid' 'high' 'mid' 'high']\n",
      "id\n",
      "4bbf498ab083a593a620a3e9    low\n",
      "4b05caf7f964a5206de322e3    mid\n",
      "58d800df9435a979b8a645fa    mid\n",
      "5614b48d498ea3525f672509    low\n",
      "4b0588def964a520b9dd22e3    mid\n",
      "Name: rating_category, dtype: object\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(x_trainset,y_trainset)\n",
    "LR_pred = LR.predict(x_testset)\n",
    "LR_prob = LR.predict_proba(x_testset)\n",
    "print(LR)\n",
    "print (LR_pred [0:5])\n",
    "print (y_testset[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "['mid' 'mid' 'mid' 'mid' 'mid']\n",
      "id\n",
      "4bbf498ab083a593a620a3e9    low\n",
      "4b05caf7f964a5206de322e3    mid\n",
      "58d800df9435a979b8a645fa    mid\n",
      "5614b48d498ea3525f672509    low\n",
      "4b0588def964a520b9dd22e3    mid\n",
      "Name: rating_category, dtype: object\n"
     ]
    }
   ],
   "source": [
    "clf_svc = svm.SVC(kernel='rbf')\n",
    "clf_svc.fit(x_trainset, y_trainset) \n",
    "svc_pred = clf_svc.predict(x_testset)\n",
    "print(clf_svc)\n",
    "print (svc_pred [0:5])\n",
    "print (y_testset[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTrees Train set Accuracy:  0.9523809523809523\n",
      "DecisionTrees Test set Accuracy:  0.7272727272727273\n",
      "DecisionTrees jaccard_similarity_score:  0.7272727272727273\n",
      "DecisionTrees f1:  0.7132867132867133\n",
      "KNN Train set Accuracy:  0.6428571428571429\n",
      "KNN Test set Accuracy:  0.6363636363636364\n",
      "KNN jaccard_similarity_score: 0.6363636363636364\n",
      "KNN f1: 0.5606060606060606\n",
      "Logistic Regression Train set Accuracy: 0.8809523809523809\n",
      "Logistic Regression Test set Accuracy: 0.36363636363636365\n",
      "Logistic Regression jaccard_similarity_score:  0.36363636363636365\n",
      "svc Train set Accuracy:  0.8571428571428571\n",
      "svc Test set Accuracy:  0.45454545454545453\n",
      "svc jaccard_similarity_score: 0.45454545454545453\n",
      "svc f1: 0.2840909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomohiro.a.nakamura\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"DecisionTrees Train set Accuracy: \", metrics.accuracy_score(y_trainset, rating_category_tree.predict(x_trainset)))\n",
    "print(\"DecisionTrees Test set Accuracy: \", metrics.accuracy_score(y_testset, tree_pred))\n",
    "print(\"DecisionTrees jaccard_similarity_score: \", jaccard_similarity_score(y_testset, tree_pred))\n",
    "print(\"DecisionTrees f1: \", f1_score(y_testset, tree_pred, average='weighted'))\n",
    "\n",
    "print(\"KNN Train set Accuracy: \", metrics.accuracy_score(y_trainset, neigh.predict(x_trainset)))\n",
    "print(\"KNN Test set Accuracy: \", metrics.accuracy_score(y_testset, KNN_pred))\n",
    "print('KNN jaccard_similarity_score:', jaccard_similarity_score(y_testset, KNN_pred))\n",
    "print('KNN f1:', f1_score(y_testset, KNN_pred, average='weighted'))\n",
    "\n",
    "print('Logistic Regression Train set Accuracy:', metrics.accuracy_score(y_trainset, LR.predict(x_trainset)))\n",
    "print('Logistic Regression Test set Accuracy:', metrics.accuracy_score(y_testset, LR_pred))\n",
    "print('Logistic Regression jaccard_similarity_score: ', jaccard_similarity_score(y_testset, LR_pred))\n",
    "\n",
    "print(\"svc Train set Accuracy: \", metrics.accuracy_score(y_trainset, clf_svc.predict(x_trainset)))\n",
    "print(\"svc Test set Accuracy: \", metrics.accuracy_score(y_testset, svc_pred))\n",
    "print('svc jaccard_similarity_score:', jaccard_similarity_score(y_testset, svc_pred))\n",
    "print('svc f1:', f1_score(y_testset, svc_pred, average='weighted'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "The metrics being used for comparing 4 different classification models are as follows; accuracy score,  Jaccard similarity score, and F1 score. The complete list of metric scores on each model is described on Fig 1: Metric Scores. The result clearly indicates that Decision Tree has the highest score on all the metrics.\n",
    "\n",
    "### Discussion\n",
    "\n",
    "The result indicates the model based on Decision Tree is the most powerful as a classification model for highly rated venues. On the other hand, the result has 2 major limitations. Firstly, the size of data is relatively small for building a machine learning model. Secondly,  there might be other types of data should be considered regarding the model building process such as the data on users since the rating scores could be affected by the preference of highly active users on Foursquare.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Although there could be potential limitations on the result of this project, the result shows that among 4 models, Decision Tree is the most powerful classification model for identifying possibly highly rated venues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
